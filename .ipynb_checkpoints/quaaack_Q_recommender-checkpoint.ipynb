{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# QUAAACK - Q: Question & Quality Framing",
        "Scalable AI Recommendation System for Large Datasets (movies, courses, products)",
        "",
        "This notebook captures the **Q** step of the QUAAACK model: framing the question and defining what quality looks like before you build. Adapt any placeholder text to your context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checklist for the Q stage",
        "- Clarify the core user question this recommender must answer.",
        "- Define success metrics (offline + operational) and acceptance thresholds.",
        "- Note assumptions about data scale, sparsity, and latency.",
        "- Specify explainability expectations for the Streamlit UI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q1. Problem / Question Statement",
        "- **User need**: help users quickly discover relevant movies, courses, or products.",
        "- **Task type**: top-N personalized ranking and similar-item lookup; optionally cold-start suggestions.",
        "- **Scope**: English content; web + mobile; Streamlit demo; domains: movies, MOOCs, e-commerce products.",
        "- **Success question**: What observable change shows the recommender works? (e.g., higher click-through vs popularity baseline).",
        "- **Hypotheses**:",
        "  - H1: Implicit-feedback collaborative filtering improves NDCG@10 over a popularity baseline by __%.",
        "  - H2: Content embeddings (plot, syllabus, product text) reduce cold-start error and improve Precision@10 by __%.",
        "- **Constraints**: p95 latency < 300 ms per request; daily model refresh; respect dataset licenses and PII hygiene."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q2. Quality & Evaluation Plan",
        "- **Offline metrics**: NDCG@k, HR@k, MAP, coverage, novelty/diversity.",
        "- **Operational SLOs**: p95 latency <300 ms; batch index build time < X minutes; memory budget <= Y GB.",
        "- **Ablations**: popularity baseline, CF-only, content-only, hybrid with tunable weights; SVD rank sweeps.",
        "- **Data quality checks**: sparsity levels, user/item frequency cutoffs, chronological splits to avoid leakage.",
        "- **Explainability bar**: for each recommendation surface the top contributing liked item (\"because you liked X\").",
        "- **Failure criteria**: launch blocked if metrics do not beat baseline by the agreed deltas or if SLOs are missed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q3. Big Data Considerations",
        "- **Datasets**: MovieLens 25M; Amazon Reviews (selected categories); internal logs if available.",
        "- **Scale challenges**: high sparsity, skewed item popularity, incremental updates.",
        "- **Efficiency tactics**: implicit feedback matrices, truncated SVD for dimensionality reduction, ANN for similarity search (e.g., Faiss), batch scoring for homepages.",
        "- **Storage/layout**: keep interactions as Parquet; precompute item embeddings; shard indexes by domain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q4. Streamlit UI Hooks (for later phases)",
        "- User selector or search box; item selector for similar-items mode.",
        "- Recommended items list with scores and short reasons (liked-item anchors).",
        "- Filters: domain (movies/courses/products), recency, diversity toggle.",
        "- Logging: capture clicks to feed back into implicit signals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment Log Template",
        "| Date | Variant | Params | Metric@k | Latency | Outcome |",
        "| ---- | ------- | ------ | -------- | ------- | ------- |",
        "|      |         |        |          |         |         |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Minimal popularity baseline for sanity checks (replace with real data)",
        "import pandas as pd",
        "",
        "# Toy interactions; replace with MovieLens/Amazon slices",
        "interactions = pd.DataFrame(",
        "    {",
        "        \"user_id\": [1,1,2,2,2,3,3,4,4,4],",
        "        \"item_id\": [101,102,101,103,104,104,105,101,104,106],",
        "        \"rating\": [1]*10,  # implicit feedback",
        "    }",
        ")",
        "",
        "popular = interactions.groupby(\"item_id\").size().sort_values(ascending=False)",
        "",
        "def recommend_popular(top_n=5):",
        "    return popular.head(top_n).index.tolist()",
        "",
        "print(\"Top popular items:\", recommend_popular())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simple \"because you liked X\" reason generator",
        "import random",
        "",
        "user_likes = interactions.groupby(\"user_id\")[\"item_id\"].apply(list)",
        "",
        "def explain_recommendation(user_id, recommended_item):",
        "    liked = user_likes.get(user_id, [])",
        "    anchor = random.choice(liked) if liked else None",
        "    if anchor:",
        "        return f\"Recommended because you liked item {anchor}.\"",
        "    return \"Recommended based on similar users/items.\"",
        "",
        "print(explain_recommendation(2, 104))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}