{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7737cf26",
   "metadata": {},
   "source": [
    "# QUAAACK – Q: Question & Quality Framing\n",
    "Scalable AI Recommendation System for Large Datasets (movies, courses, products)\n",
    "\n",
    "> This notebook captures the **Q** stage of the QUAAACK model: precise problem/question framing and quality targets. If you use a different definition for \"Q\", tell me and I’ll adapt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd083e60",
   "metadata": {},
   "source": [
    "## Portfolio Compliance Snapshot\n",
    "- Follow IU portfolio order: Phase 1 → Phase 2 → Phase 3. Submit each Portfolioteil in PebblePad; re-upload updated P1 & P2 with P3. Verification and final feedback happen in Atlas.\n",
    "- Page limits: P1 & P2 texts ≤ 0.5 page each; P3 abstract = 2 pages.\n",
    "- Include Eidesstattliche Erklärung via myCampus; adhere to IU citation and literature rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f8ef2",
   "metadata": {},
   "source": [
    "## Q1. Problem / Question Statement (Phase 1 core)\n",
    "- **User need**: e.g., help users discover relevant movies/courses/products quickly.\n",
    "- **Problem formulation**: What ranking task are we solving (top-N recommendation, similar-items, or cold-start suggestions)?\n",
    "- **Scope**: domains in/out; markets; languages; devices.\n",
    "- **Success question**: *What observable change shows the recommender works?*\n",
    "- **Hypotheses**:\n",
    "  - H1: Collaborative filtering with implicit feedback improves NDCG@10 vs popularity baseline by __%.\n",
    "  - H2: Adding content embeddings improves cold-start precision@10 by __%.\n",
    "- **Constraints**: latency <300 ms; memory budget; privacy/licensing on datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d526051",
   "metadata": {},
   "source": [
    "### Fill your Phase 1 concept text (≤0.5 page)\n",
    "- Goal & target metric: …\n",
    "- Target users/items: …\n",
    "- Primary question to answer: …\n",
    "- Planned methods (CF, content, hybrid, SVD): …\n",
    "- Data sources (MovieLens 25M, Amazon Reviews, internal logs): …\n",
    "- Early sketch link/path: …\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a2d23",
   "metadata": {},
   "source": [
    "## Q2. Quality & Evaluation Plan (set now, track through phases)\n",
    "- **Offline metrics**: NDCG@k, HR@k, MAP, coverage, novelty/diversity.\n",
    "- **Operational SLOs**: p95 latency <300 ms; index build time <X min; model update cadence.\n",
    "- **Ablations**: popularity baseline, CF-only, content-only, hybrid weights.\n",
    "- **Data quality checks**: sparsity levels, user/item frequency cutoffs, leakage guard (chronological splits).\n",
    "- **Acceptance bar**: minimum metric deltas over baseline; failure criteria.\n",
    "- **Explainability requirement**: for each recommendation, surface the top contributing liked item (\"because you liked X\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5272c",
   "metadata": {},
   "source": [
    "### Experiment table (extend during Phase 2)\n",
    "| Date | Variant | Params | Metric@k | Latency | Outcome |\n",
    "| ---- | ------- | ------ | -------- | ------- | ------- |\n",
    "|      |         |        |          |         |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0dbd7e",
   "metadata": {},
   "source": [
    "## Q3. Stakeholders, Risks, Ethics\n",
    "- Stakeholders: end users, content owners, platform ops, compliance.\n",
    "- Risks: popularity bias, cold start, filter bubbles, data drift, PII leakage.\n",
    "- Mitigations: content backfill, diversity re-ranking, regular retrains, min events thresholds, anonymization.\n",
    "- Compliance: dataset licenses; citation of sources; align with IU formalia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238fbc7",
   "metadata": {},
   "source": [
    "## Phase 2 Notes (implementation + reflection, ≤0.5 page for submission)\n",
    "- Status vs plan: …\n",
    "- What changed about the core question or metrics: …\n",
    "- Evidence (prototype screenshot / Streamlit run): …\n",
    "- Next hypotheses or ablations: …\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ef1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality baseline example: popularity recommender for comparison\n",
    "# import pandas as pd\n",
    "# interactions = pd.read_csv(\"data/interactions.csv\")\n",
    "# popular = interactions.groupby('item_id').size().sort_values(ascending=False)\n",
    "# def recommend_popular(top_n=10):\n",
    "#     return list(popular.head(top_n).index)\n",
    "# print(recommend_popular(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf6952",
   "metadata": {},
   "source": [
    "## Phase 3 Abstract Skeleton (2 pages)\n",
    "- Restate the question and success criteria.\n",
    "- Methods tried; which answered the question best and why.\n",
    "- Results vs acceptance bar (metrics + latency).\n",
    "- Reflection: where the question evolved; remaining open questions.\n",
    "- Resources: data, software, versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27fb716",
   "metadata": {},
   "source": [
    "## Attachments / Artefacts (fill in before submission)\n",
    "- Phase 1 concept file: …\n",
    "- Phase 2 draft file: …\n",
    "- Abstract PDF: …\n",
    "- Streamlit app entrypoint: `app.py`\n",
    "- Models/data paths: …\n",
    "- Optional resources zip: …\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
